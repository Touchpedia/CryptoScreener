from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
import asyncio, os, time
from redis import Redis
from rq import Queue
import psycopg2

# CCXT for dynamic top symbols
import ccxt

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- Redis/RQ config ---
REDIS_HOST = os.getenv("REDIS_HOST", "redis")
REDIS_PORT = int(os.getenv("REDIS_PORT", "6379"))
RQ_QUEUE   = os.getenv("RQ_QUEUE", "ingestion-tasks")

# --- Timescale/PG settings (coverage + flush) ---
DB_HOST = os.getenv("POSTGRES_HOST", "postgres")
DB_PORT = os.getenv("POSTGRES_PORT", "5432")
DB_USER = os.getenv("POSTGRES_USER", "postgres")
DB_PASS = os.getenv("POSTGRES_PASSWORD", "postgres")
DB_NAME = os.getenv("POSTGRES_DB", "postgres")

def tf_to_ms(tf: str) -> int:
    tf = (tf or "1m").lower()
    if tf.endswith("m"):
        return int(tf[:-1]) * 60_000
    if tf.endswith("h"):
        return int(tf[:-1]) * 60 * 60_000
    if tf.endswith("d"):
        return int(tf[:-1]) * 24 * 60 * 60_000
    return 60_000

def get_dynamic_top_symbols(n: int) -> list[str]:
    """
    Pull top N USDT symbols by 24h volume from Binance via CCXT.
    Fallback to majors list on any error.
    """
    n = max(1, min(int(n or 1), 200))
    try:
        ex = ccxt.binance({"enableRateLimit": True})
        # fetch tickers is cheapest for volume sorting
        tickers = ex.fetch_tickers()  # dict of {symbol: ticker}
        rows = []
        for sym, t in tickers.items():
            # we only care about USDT quote and spot (no contracts)
            if not sym.endswith("/USDT"):
                continue
            # choose the best available volume field
            vol = None
            # CCXT standard has 'quoteVolume' on binance
            if isinstance(t, dict):
                vol = t.get("quoteVolume") or t.get("baseVolume") or 0
            try:
                vol = float(vol)
            except Exception:
                vol = 0.0
            rows.append((sym, vol))
        rows.sort(key=lambda x: x[1], reverse=True)
        symbols = [s for (s, _) in rows[:n]]
        if symbols:
            return symbols
        # if empty (unlikely), fall through to majors
    except Exception as e:
        print(f"⚠️ CCXT top symbols failed: {e}")

    majors = [
        "BTC/USDT","ETH/USDT","BNB/USDT","SOL/USDT","XRP/USDT","ADA/USDT","DOGE/USDT",
        "TON/USDT","TRX/USDT","LINK/USDT","DOT/USDT","MATIC/USDT","LTC/USDT","BCH/USDT",
        "AVAX/USDT","XLM/USDT","UNI/USDT","ATOM/USDT","ETC/USDT","APT/USDT","NEAR/USDT",
        "OP/USDT","ARB/USDT","TIA/USDT","INJ/USDT","SUI/USDT","SEI/USDT","FIL/USDT",
        "AAVE/USDT","ALGO/USDT","EGLD/USDT","FTM/USDT","RON/USDT","HNT/USDT","RUNE/USDT"
    ]
    return majors[:n]

@app.get("/api/status")
async def status():
    return {"status": "ok"}

@app.post("/api/ingestion/run")
async def run_ingestion(request: Request):
    """
    Enqueue jobs with explicit window:
      workers.backfill_range_job(symbol, timeframe, start_ts, end_ts)
    start_ts/end_ts are ms since epoch UTC.
    """
    try:
        body = await request.json()
    except Exception:
        body = {}

    top_symbols        = int(body.get("top_symbols", 100))
    interval           = str(body.get("interval", "1m"))
    candles_per_symbol = int(body.get("candles_per_symbol", 6000))

    # 🔹 dynamic list from exchange
    symbols = get_dynamic_top_symbols(top_symbols)

    # window covering requested candles
    tf_ms   = tf_to_ms(interval)
    now_ms  = int(time.time() * 1000)
    start_ts = max(0, now_ms - (candles_per_symbol + 2) * tf_ms)
    end_ts   = now_ms

    conn = Redis(host=REDIS_HOST, port=REDIS_PORT, db=0)
    q = Queue(RQ_QUEUE, connection=conn, default_timeout=900)

    for sym in symbols:
        q.enqueue("workers.backfill_range_job", sym, interval, start_ts, end_ts)

    msg = f"Enqueued {len(symbols)} jobs on {RQ_QUEUE} (interval={interval}, candles={candles_per_symbol})"
    print(f"▶ {msg}; window: {start_ts}->{end_ts} tf_ms={tf_ms}; symbols[0:5]={symbols[:5]}")
    return {"message": msg, "symbols": symbols, "start_ts": start_ts, "end_ts": end_ts, "tf_ms": tf_ms}

@app.get("/api/report/coverage")
async def report_coverage():
    """Fetch coverage stats; auto-detect ts column."""
    tables = ["candles", "staging_candles"]
    time_cols = ["time","timestamp","open_time","ts","t_open"]
    result = []

    for tbl in tables:
        try:
            conn = psycopg2.connect(host=DB_HOST, port=DB_PORT, user=DB_USER, password=DB_PASS, dbname=DB_NAME)
            cur = conn.cursor()
            cur.execute("SELECT column_name FROM information_schema.columns WHERE table_name = %s", (tbl,))
            cols = [r[0] for r in cur.fetchall()]
            time_col = next((c for c in time_cols if c in cols), None)
            if not time_col:
                raise Exception(f"No time-like column in {tbl}")

            q = f"""
            SELECT symbol, COUNT(*) AS received, MAX({time_col}) AS latest_ts
            FROM {tbl}
            GROUP BY symbol
            ORDER BY symbol
            LIMIT 300;
            """
            cur.execute(q)
            rows = cur.fetchall()
            cur.close(); conn.close()

            if rows:
                for (symbol, received, latest_ts) in rows:
                    result.append({
                        "symbol": symbol,
                        "total_required": 6000,
                        "received": received,
                        "latest_ts": str(latest_ts) if latest_ts else "-"
                    })
                print(f"✅ data fetched from {tbl} using column {time_col}")
                break
        except Exception as e:
            print(f"⚠️ table {tbl} failed: {e}")
            continue

    return {"rows": result}

@app.post("/api/db/flush")
async def flush_db():
    conn = psycopg2.connect(host=DB_HOST, port=DB_PORT, user=DB_USER, password=DB_PASS, dbname=DB_NAME)
    cur = conn.cursor()
    cur.execute("TRUNCATE TABLE staging_candles, candles RESTART IDENTITY CASCADE;")
    conn.commit()
    cur.close(); conn.close()
    print("✅ Database flushed")
    return {"message": "Database flushed successfully"}
